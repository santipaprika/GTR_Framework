//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
depth quad.vs depth.fs
multi basic.vs multi.fs
noLights basic.vs noLights.fs
phong basic.vs phong.fs
phongShadows basic.vs phongShadows.fs
phongAAShadows basic.vs phongAAShadows.fs
gbuffers basic.vs gbuffers.fs
deferred quad.vs deferred.fs
// lights pass
deferredPhong quad.vs deferredPhong.fs
deferredPhongShadows quad.vs deferredPhongShadows.fs
deferredPhongAAShadows quad.vs deferredPhongAAShadows.fs
// lights pass with geometry
deferredPhongGeometry basic.vs deferredPhong.fs
deferredPhongShadowsGeometry basic.vs deferredPhongShadows.fs
deferredPhongAAShadowsGeometry basic.vs deferredPhongAAShadows.fs

// --------------------------------------------------------------------------

\getTextureUniforms
uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_alpha_cutoff;
uniform float u_tiles_number;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_occlusion_texture;

// --------------------------------------------------------------------------

\getColor
vec2 uv = v_uv;
vec4 color = u_color;
color *= texture2D( u_texture, uv * u_tiles_number);

if(color.a < u_alpha_cutoff)
	discard;

// --------------------------------------------------------------------------

\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_uv;
out vec2 v_uv;

void main()
{	
	v_uv = a_uv;
	gl_Position = vec4( a_vertex, 1.0 );
}


\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	FragColor = u_color;
}


\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;
uniform float u_tiles_number;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;
}


\multi.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;
uniform float u_tiles_number;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv * u_tiles_number);

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	FragColor = color;
	NormalColor = vec4(N,1.0);
}


\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	FragColor = vec4(color);
}


\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}


\noLights.fs

#version 330 core

in vec2 v_uv; //texture coordinates

uniform vec4 u_color;
uniform float u_alpha_cutoff;
uniform vec3 u_ambient_light;
uniform sampler2D u_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_occlusion_texture;
uniform float u_tiles_number;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	
	//ambient
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz;

	FragColor = color;
}


\phong.fs

#version 330 core

in vec3 v_world_position; //position in world coords
in vec3 v_normal; //normal in the pixel
in vec2 v_uv; //texture coordinates

uniform float u_alpha_cutoff;
uniform vec4 u_color;
uniform vec3 u_ambient_light;
uniform sampler2D u_texture;
uniform sampler2D u_occlusion_texture;
uniform sampler2D u_emissive_texture;
uniform float u_tiles_number;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_maxdist;
uniform float u_light_intensity;
uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

out vec4 FragColor;

float getAttenuation()
{	
	//compute distance
	float light_distance = length(u_light_position - v_world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(v_normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - v_world_position);
		
		//compute how much is aligned
		float NdotL = dot(N,L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation();
		
		if (u_light_type == 1)	{//point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D,-L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	//function that returns the light using phong
	light = computeLight(light);
	
	//add the ambient light
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz;
	
	FragColor = color;
}

// ----------------------------------------------------------------------

\phongShadows.fs

#version 330 core

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform float u_alpha_cutoff;
uniform vec4 u_color;
uniform vec3 u_ambient_light;
uniform sampler2D u_texture;
uniform sampler2D u_occlusion_texture;
uniform sampler2D u_emissive_texture;
uniform float u_tiles_number;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_maxdist;
uniform float u_light_intensity;
uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

uniform sampler2D u_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

#define NUM_FACES 6
uniform mat4 u_shadowmap_viewprojs[6];

out vec4 FragColor;

float getAttenuation()
{	
	//compute distance
	float light_distance = length(u_light_position - v_world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(v_normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - v_world_position);
		
		//compute how much is aligned
		float NdotL = dot(N,L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation();
		
		if (u_light_type == 1)	{//point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D,-L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

bool getShadowFactorPointLight()
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(v_world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return false;
		
		if( shadow_depth < real_depth )
			return false;

		break;
	}
	
	return true;
	
}

bool isShadowed()	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(v_world_position,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	//adaptative bias
	vec3 N = normalize(v_normal);
	vec3 L;
	
	bool dark_outside; //add or not light outside the shadow map zone
	if(u_light_type == 0) {	//directional light
		L = -normalize(u_light_direction);
		dark_outside = false;
	}
	else if (u_light_type == 2){//spot
		L =  normalize(u_light_position - v_world_position);
		dark_outside = true;
	}
	else
		return !getShadowFactorPointLight();

	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - adaptative_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return dark_outside;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return dark_outside;
	
	//read depth from depth buffer in [0..+1]
	float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;
	
	if( shadow_depth < real_depth )
		return true;
	
	return false;
}

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	
	//check if it is in shadow or not
	if (!isShadowed())
		light += computeLight(light); //function that returns the light using phong
	
	//add the ambient light
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number );
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz;
	
	FragColor = color;
}

// ----------------------------------------------------------------------


\phongAAShadows.fs

#version 330 core

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform float u_alpha_cutoff;
uniform vec4 u_color;
uniform vec3 u_ambient_light;
uniform sampler2D u_texture;
uniform sampler2D u_occlusion_texture;
uniform sampler2D u_emissive_texture;
uniform float u_tiles_number;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_maxdist;
uniform float u_light_intensity;
uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

uniform sampler2DShadow u_shadowmap_AA;
uniform sampler2D u_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

uniform float u_shadowmap_width;
uniform float u_shadowmap_height;
#define NUM_FACES 6
uniform mat4 u_shadowmap_viewprojs[6];

out vec4 FragColor;

float getAttenuation()
{	
	//compute distance
	float light_distance = length(u_light_position - v_world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(v_normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - v_world_position);
		
		//compute how much is aligned
		float NdotL = dot(N,L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation();
		
		if (u_light_type == 1)	{//point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D,-L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

float getShadowFactorPointLight()
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(v_world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return 0.0;
		
		if( shadow_depth < real_depth )
			return 0.0;

		break;
	}
	
	return 1.0;
	
}

float getShadowFactor()	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(v_world_position, 1.0);

	//from homogeneous space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//adaptative bias
	vec3 N = normalize(v_normal);
	vec3 L;
	if(u_light_type == 0) //directional light
		L = -normalize(u_light_direction);
	else if (u_light_type == 1)
		return getShadowFactorPointLight();
	else //spot
		L =  normalize(u_light_position - v_world_position);
		
	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);

	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1] (z)
	real_depth = real_depth * 0.5 + 0.5;

	//it is outside on the sides
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||
	shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			return 1.0;
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return 1.0;
	
	float xOffset = 1.0/u_shadowmap_width;
    float yOffset = 1.0/u_shadowmap_height;

	float Factor = 0.0;

    for (int y = -1 ; y <= 1 ; y++) {
        for (int x = -1 ; x <= 1 ; x++) {
            vec2 Offsets = vec2(x * xOffset, y * yOffset);
            vec3 UVC = vec3(shadow_uv + Offsets, real_depth);
            Factor += texture(u_shadowmap_AA, UVC);
        }
    }

    return (0.5 + (Factor / 18.0));
}

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	float shadowFact = getShadowFactor();
	light += shadowFact * computeLight(light); //function that returns the light using phong
	
	//add the ambient light
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz;
	
	FragColor = color;
}


// -----------------------------------------------------------------------
// -----------------------------------------------------------------------
// -----------------------------------------------------------------------
// -------------------------- DEFERRED -----------------------------------
// -----------------------------------------------------------------------
// -----------------------------------------------------------------------
// -----------------------------------------------------------------------


\gbuffers.fs

#version 330

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform float u_tiles_number;
uniform sampler2D u_texture;
uniform sampler2D u_occlusion_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;
layout(location = 2) out vec4 ExtraColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	
	if(color.a < u_alpha_cutoff)
		discard;
	
	vec4 matProperties = color * texture( u_occlusion_texture, uv * u_tiles_number);
	
	color *= texture( u_texture, uv * u_tiles_number);
	//discard some pixels depending on the pixel screen position and its transparency
	if(	color.a < 0.9 && floor(mod(gl_FragCoord.x,2.0)) != floor(mod(gl_FragCoord.y,2.0)) )
		discard;

	FragColor = color;
	
	vec3 N = v_normal;
	NormalColor = vec4(N*0.5 + vec3(0.5),1.0);
	
	ExtraColor = matProperties;
}



\deferred.fs

#version 330

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_extra_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform vec3 u_ambient_light;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_intensity;


layout(location = 0) out vec4 FragColor;

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}


void main()
{
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; //extract uvs from pixel screenpos
	vec3 color = texture( u_color_texture, uv ).xyz;
	//normals must be converted from 0..1 to -1..+1
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss
	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	
	vec3 light = vec3(0.0);
	light += texture(u_extra_texture, uv).x * u_ambient_light; // ambient
	light += getDirectionalLight(N);
	
	color *= light;
	
	FragColor = vec4(color, 1.0);
}


\deferredPhong.fs

#version 330 core

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_extra_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_maxdist;
uniform float u_light_intensity;
uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

out vec4 FragColor;

float getAttenuation(vec3 world_position)
{	
	//compute distance
	float light_distance = length(u_light_position - world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light, vec3 normal, vec3 world_position)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - world_position);
		
		//compute how much is aligned
		float NdotL = dot(N,L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation(world_position);
		
		if (u_light_type == 1)	{//point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D,-L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

void main()
{
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; //extract uvs from pixel screenpos
	vec3 color = texture( u_color_texture, uv ).xyz;
	
	//normals must be converted from 0..1 to -1..+1
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss
	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	//function that returns the light using phong
	light = computeLight(light, N, worldpos);
	
	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	//color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz;
	FragColor = vec4(color, 1.0);
	return;
	
}



\deferredPhongShadows.fs

#version 330 core

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_extra_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_maxdist;
uniform float u_light_intensity;
uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

uniform sampler2D u_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

#define NUM_FACES 6
uniform mat4 u_shadowmap_viewprojs[6];

out vec4 FragColor;

float getAttenuation(vec3 world_position)
{	
	//compute distance
	float light_distance = length(u_light_position - world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light, vec3 normal, vec3 world_position)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - world_position);
		
		//compute how much is aligned
		float NdotL = dot(N,L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation(world_position);
		
		if (u_light_type == 1)	{//point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D,-L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

bool getShadowFactorPointLight(vec3 world_position)
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return false;
		
		if( shadow_depth < real_depth )
			return false;

		break;
	}
	
	return true;
	
}

bool isShadowed(vec3 world_position, vec3 normal)	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(world_position,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	//adaptative bias
	vec3 N = normalize(normal);
	vec3 L;
	
	bool dark_outside; //add or not light outside the shadow map zone
	if(u_light_type == 0) {	//directional light
		L = -normalize(u_light_direction);
		dark_outside = false;
	}
	else if (u_light_type == 2){//spot
		L =  normalize(u_light_position - world_position);
		dark_outside = true;
	}
	else
		return !getShadowFactorPointLight(world_position);

	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - adaptative_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return dark_outside;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return dark_outside;
	
	//read depth from depth buffer in [0..+1]
	float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;
	
	if( shadow_depth < real_depth )
		return true;
	
	return false;
}

void main()
{
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; //extract uvs from pixel screenpos
	vec3 color = texture( u_color_texture, uv ).xyz;
	
	//normals must be converted from 0..1 to -1..+1
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss
	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	
	//check if it is in shadow or not
	if (!isShadowed(worldpos, N))
		light += computeLight(light, N, worldpos); //function that returns the light using phong

	//apply the light to the final pixel color
	color.xyz *= light;
	
	FragColor = vec4(color, 1.0);
}



\deferredPhongAAShadows.fs

#version 330 core

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_extra_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_maxdist;
uniform float u_light_intensity;
uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

uniform sampler2DShadow u_shadowmap_AA;
uniform sampler2D u_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

uniform float u_shadowmap_width;
uniform float u_shadowmap_height;

#define NUM_FACES 6
uniform mat4 u_shadowmap_viewprojs[6];

out vec4 FragColor;

float getAttenuation(vec3 world_position)
{	
	//compute distance
	float light_distance = length(u_light_position - world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light, vec3 normal, vec3 world_position)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - world_position);
		
		//compute how much is aligned
		float NdotL = dot(N,L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation(world_position);
		
		if (u_light_type == 1)	{//point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D,-L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

float getShadowFactorPointLight(vec3 world_position)
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return 0.0;
		
		if( shadow_depth > real_depth )
			return 1.0;
		
		float xOffset = 1.0/u_shadowmap_width;
		float yOffset = 1.0/u_shadowmap_height;

		float Factor = 0.0;

		for (int y = -1 ; y <= 1 ; y++) {
			for (int x = -1 ; x <= 1 ; x++) {
				vec2 Offsets = vec2(x * xOffset, y * yOffset);
				vec3 UVC = vec3(shadow_uv + Offsets, real_depth);
				Factor += texture(u_shadowmap_AA, UVC);
			}
		}

		return (0.5 + (Factor / 18.0));
	}
	
	//return 1.0;
	
}

float getShadowFactor(vec3 world_position, vec3 normal)	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(world_position,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	//adaptative bias
	vec3 N = normalize(normal);
	vec3 L;
	
	float light_outside = 1.0; //add or not light outside the shadow map zone
	if(u_light_type == 0) {	//directional light
		L = -normalize(u_light_direction);
		light_outside = 1.0;
	}
	else if (u_light_type == 2){//spot
		L =  normalize(u_light_position - world_position);
		light_outside = 0.0;
	}
	else
		return getShadowFactorPointLight(world_position);
	
	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	//adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - adaptative_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return light_outside;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return light_outside;
	
	float xOffset = 1.0/u_shadowmap_width;
    float yOffset = 1.0/u_shadowmap_height;

	float Factor = 0.0;

    for (int y = -1 ; y <= 1 ; y++) {
        for (int x = -1 ; x <= 1 ; x++) {
            vec2 Offsets = vec2(x * xOffset, y * yOffset);
            vec3 UVC = vec3(shadow_uv + Offsets, real_depth);
            Factor += texture(u_shadowmap_AA, UVC);
        }
    }

    return (0.5 + (Factor / 18.0));
	
	
}

void main()
{
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; //extract uvs from pixel screenpos
	vec3 color = texture( u_color_texture, uv ).xyz;
	
	//normals must be converted from 0..1 to -1..+1
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss
	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	
	float shadowFact = getShadowFactor(worldpos, N);
	light += shadowFact * computeLight(light, N, worldpos); //function that returns the light using phong

	//apply the light to the final pixel color
	color.xyz *= light;
	
	FragColor = vec4(color, 1.0);
}
