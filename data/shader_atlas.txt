//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
depth quad.vs depth.fs
multi basic.vs multi.fs
// --- FORWARD --- 
noLights basic.vs noLights.fs
light basic.vs light.fs
lightShadows basic.vs lightShadows.fs
lightAAShadows basic.vs lightAAShadows.fs
// --- DEFERRED ---
gbuffers basic.vs gbuffers.fs
deferred quad.vs deferred.fs
// Lights pass (basic)
deferredLight quad.vs deferredLight.fs
deferredLightShadows quad.vs deferredLightShadows.fs
deferredLightAAShadows quad.vs deferredLightAAShadows.fs
// Lights pass with geometry
deferredLightGeometry basic.vs deferredLight.fs
deferredLightShadowsGeometry basic.vs deferredLightShadows.fs
deferredLightAAShadowsGeometry basic.vs deferredLightAAShadows.fs
// Forward passes for blend materials
deferredBlend basic.vs deferredBlend.fs
deferredBlendShadows basic.vs deferredBlendShadows.fs
deferredBlendAAShadows basic.vs deferredBlendAAShadows.fs
// degamma shader
degammaDeferred quad.vs degammaDeferred.fs
// screen space ambient occlusion
ssao quad.vs ssao.fs
blur quad.vs blur.fs
// Probes
probe basic.vs probe.fs
// Reflection
reflection quad.vs reflection.fs
reflectionProbe basic.vs reflectionProbe.fs
// Skybox
skybox basic.vs skybox.fs
// Volume scattering
volumetric quad.vs volumetric.fs
// Decals
decal basic.vs decal.fs
// Tone Mapping
toneMapper quad.vs toneMapper.fs
 
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// ------------------------------------------------------- INCLUDES --------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------

\getTextureUniforms
uniform float u_alpha_cutoff;
uniform vec4 u_color;
uniform vec3 u_ambient_light;
uniform sampler2D u_texture;
uniform sampler2D u_occlusion_texture;
uniform sampler2D u_emissive_texture;
uniform vec3 u_emissive_factor;
uniform float u_tiles_number;

// -------------------------------------------------------------------------------------------------------------------------

\getLightUniforms
uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_maxdist;
uniform float u_light_intensity;
uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

// -------------------------------------------------------------------------------------------------------------------------

\getShadowUniforms
uniform sampler2DShadow u_shadowmap_AA;
uniform sampler2D u_shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

uniform float u_shadowmap_width;
uniform float u_shadowmap_height;

#define NUM_FACES 6
uniform mat4 u_shadowmap_viewprojs[6];

// -------------------------------------------------------------------------------------------------------------------------

\getDeferredUniforms
uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

// -------------------------------------------------------------------------------------------------------------------------

\PBRForwardCode
if (u_light_type == 0) // directional 						//Light ray
	mat.L = normalize(-u_light_direction);
else mat.L = normalize(u_light_position - v_world_position);
mat.V = normalize(u_camera_pos - v_world_position);	//View ray
mat.N = normalize(v_normal); 								//Normal ray
mat.R = normalize(reflect(mat.V, mat.N)); 					//Reflected ray
mat.H = normalize(mat.V + mat.L); 							//Half 
	
mat.NdotH = clamp( dot(mat.N,mat.H), 0.0, 1.0 );
mat.NdotV = clamp( dot(mat.N,mat.V), 0.0, 1.0 );
mat.NdotL = clamp( dot(mat.N,mat.L), 0.0, 1.0 );
mat.LdotH = clamp( dot(mat.L,mat.H), 0.0, 1.0 );

vec4 mat_properties = texture( u_occlusion_texture, uv * u_tiles_number);
mat.albedo = texture( u_texture, uv * u_tiles_number).xyz;
mat.roughness = mat_properties.y * u_roughness_factor;
mat.metalness = mat_properties.z * u_metallic_factor;

//we compute the reflection in base to the color and the metalness
vec3 f0 = mat.albedo * mat.metalness + (vec3(0.5) * (1.0 - mat.metalness));

//metallic materials do not have diffuse
vec3 diffuseColor = (1.0 - mat.metalness) * mat.albedo;

//compute the specular
vec3 Fr_d = specularBRDF(mat.roughness, f0, mat.NdotH, mat.NdotV, mat.NdotL, mat.LdotH);

// Here we use the Burley, but you can replace it by the Lambert.
float linearRoughness = pow(mat.roughness, 2);
vec3 Fd_d = diffuseColor * Fd_Burley(mat.NdotV, mat.NdotL, mat.LdotH, linearRoughness); 

//add diffuse and specular reflection
vec3 direct = Fr_d + Fd_d;

// -------------------------------------------------------------------------------------------------------------------------

\PBRDeferredCode
if (u_light_type == 0) // directional 						//Light ray
	mat.L = normalize(-u_light_direction);
else mat.L = normalize(u_light_position - worldpos);
mat.V = normalize(u_camera_pos - worldpos);					//View ray
mat.N = N; 													//Normal ray
mat.R = normalize(reflect(mat.V, mat.N)); 					//Reflected ray
mat.H = normalize(mat.V + mat.L); 							//Half Vector

mat.NdotH = clamp( dot(mat.N,mat.H), 0.0, 1.0 );
mat.NdotV = clamp( dot(mat.N,mat.V), 0.0, 1.0 );
mat.NdotL = clamp( dot(mat.N,mat.L), 0.0, 1.0 );
mat.LdotH = clamp( dot(mat.L,mat.H), 0.0, 1.0 );

mat.albedo = texture( u_color_texture, uv ).xyz;
mat.metalness = texture( u_color_texture, uv ).w;
mat.roughness = texture( u_normal_texture, uv ).w;

//we compute the reflection in base to the color and the metalness
vec3 f0 = mat.albedo * mat.metalness + (vec3(0.5) * (1.0 - mat.metalness));

//metallic materials do not have diffuse
vec3 diffuseColor = (1.0 - mat.metalness) * mat.albedo;

//compute the specular
//vec3 Fr_d = specularBRDF(mat.roughness, f0, mat.NdotH, mat.NdotV, mat.NdotL, mat.LdotH);
float mip_level = mat.roughness;

vec3 Fr_d = vec3(0.0);

if (u_exists_cubemap)
	//Fr_d = textureLod( u_cubemap_texture, mat.R, mip_level ).xyz;
	Fr_d = specularBRDF(mat.roughness, f0, mat.NdotH, mat.NdotV, mat.NdotL, mat.LdotH);
else
	Fr_d = specularBRDF(mat.roughness, f0, mat.NdotH, mat.NdotV, mat.NdotL, mat.LdotH);

// Here we use the Burley, but you can replace it by the Lambert.
float linearRoughness = pow(mat.roughness, 2);
vec3 Fd_d = diffuseColor * Fd_Burley(mat.NdotV, mat.NdotL, mat.LdotH, linearRoughness); 

//add diffuse and specular reflection
vec3 direct = Fr_d + Fd_d;

// -------------------------------------------------------------------------------------------------------------------------

\PBRFunctions
uniform vec3 u_camera_pos;
uniform int illumination_technique;
uniform samplerCube u_cubemap_texture;
uniform bool u_exists_cubemap;
uniform float u_roughness_factor;
uniform float u_metallic_factor;

// Material struct where we will be storing the data
struct Material 
{
    // Vectors
	vec3 V, N, R, L, H;
	
	// Dot products
	float NdotV;
	float LdotH;
	float NdotL;
	float NdotH;

	// Properties
	vec3 albedo;
    float metalness;
	float roughness;
	vec3 diffuse;
	vec3 specular;
} mat;

#define PI 3.1415926535897932384626433832795

// Normal Distribution Function using GGX Distribution
float D_GGX ( const in float NoH, const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

// Fresnel term with scalar optimization(f90=1)
vec3 F_Schlick( const in float VoH, const in vec3 f0 )
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX( float NdotV, float k )
{
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness )
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}

//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, float NoH, float NoV, float NoL, float LoH )
{
	float a = roughness * roughness;

	// Normal Distribution Function
	float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}

float F_Schlick(float u, float f0, float f90) {
    return f0 + (f90 - f0) * pow(1.0 - u, 5.0);
}

#define RECIPROCAL_PI 0.3183098861837697

// Diffuse Reflections: Disney BRDF using retro-reflections using F term, this is much more complex!!
float Fd_Burley ( const in float NoV, const in float NoL, const in float LoH, const in float linearRoughness )
{
        float f90 = 0.5 + 2.0 * linearRoughness * LoH * LoH;
        float lightScatter = F_Schlick( NoL, 1.0, f90 );
        float viewScatter  = F_Schlick( NoV, 1.0, f90 );
        return lightScatter * viewScatter * RECIPROCAL_PI;
}

// -------------------------------------------------------------------------------------------------------------------------

\lightForwardFunctions
float getAttenuation()
{	
	//compute distance
	float light_distance = length(u_light_position - v_world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N, L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(v_normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - v_world_position);
		
		//compute how much is aligned
		float NdotL = dot(N, L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation();
		
		if (u_light_type == 1)	{  //point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D, -L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

// -------------------------------------------------------------------------------------------------------------------------

\lightDeferredFunctions
float getAttenuation(vec3 world_position)
{	
	//compute distance
	float light_distance = length(u_light_position - world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist;

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 computeLight(vec3 light, vec3 normal, vec3 world_position)
{
	//very important to normalize as they come interpolated so normalization is lost
	vec3 N = normalize(normal);
	
	if( u_light_type == 0 ) {	//directional  light
		//store the amount of diffuse light
		return getDirectionalLight(N);
	}	
	else //point and spot light
	{
		//light vector
		vec3 L = normalize(u_light_position - world_position);
		
		//compute how much is aligned
		float NdotL = dot(N, L);
		
		//light cannot be negative (but the dot product can)
		NdotL = clamp( NdotL, 0.0, 1.0 );
		light += (NdotL * u_light_color) * getAttenuation(world_position);
		
		if (u_light_type == 1)	{   //point light
			return light * u_light_intensity;
		}	
		else	//spot light
		{
			vec3 D = normalize(u_light_direction);
			float spotCosine = dot(D, -L);
			if (spotCosine >= u_light_spotCosineCutoff)
				return light * pow(spotCosine,u_light_spotExponent) * u_light_intensity;
			else return vec3(0.0);
		}
	}
}

// -------------------------------------------------------------------------------------------------------------------------

\reconstructFromGBuffers
vec2 uv = (gl_FragCoord.xy) * u_iRes.xy; //extract uvs from pixel screenpos
vec3 color = texture( u_color_texture, uv ).xyz;
	
//normals must be converted from 0..1 to -1..+1
vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
N = normalize(N); //always normalize in case of data loss
//reconstruct world position from depth and inv. viewproj
float depth = texture( u_depth_texture, uv ).x;
vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

// -------------------------------------------------------------------------------------------------------------------------

\gammaFunctions
vec3 degamma(vec3 c)
{
    return pow(c,vec3(2.2));
}

vec3 gamma(vec3 c)
{
    return pow(c,vec3(1.0/2.2));
}

// -------------------------------------------------------------------------------------------------------------------------

\shCode

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}

\blank
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// ------------------------------------------------------- SHADERS ---------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------

\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

// -------------------------------------------------------------------------------------------------------------------------

\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_uv;
out vec2 v_uv;

void main()
{	
	v_uv = a_uv;
	gl_Position = vec4( a_vertex, 1.0 );
}

// -------------------------------------------------------------------------------------------------------------------------

\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	FragColor = u_color;
}

// -------------------------------------------------------------------------------------------------------------------------

\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;
uniform float u_tiles_number;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\multi.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;
uniform float u_tiles_number;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv * u_tiles_number);

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	FragColor = color;
	NormalColor = vec4(N,1.0);
}

// -------------------------------------------------------------------------------------------------------------------------

\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	FragColor = vec4(color);
}

// -------------------------------------------------------------------------------------------------------------------------

\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}
\blank
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// ------------------------------------------------------- FORWARD ---------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------

\noLights.fs

#version 330 core

in vec2 v_uv; //texture coordinates

#include "getTextureUniforms"

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	
	//ambient
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz * u_emissive_factor;

	FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\light.fs

#version 330 core

in vec3 v_world_position; //position in world coords
in vec3 v_normal; //normal in the pixel
in vec2 v_uv; //texture coordinates

#include "getTextureUniforms"

#include "getLightUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightForwardFunctions"

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	if (illumination_technique == 1) //PBR
	{
		vec3 lightParams = computeLight(light);
		
		#include "PBRForwardCode"

		//function that returns the light using phong
		light += direct * lightParams;
	}
	else //Phong
		light += computeLight(light);
	
	//add the ambient light
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz * u_emissive_factor;
	
	FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\lightShadows.fs

#version 330 core

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

#include "getTextureUniforms"

#include "getLightUniforms"

#include "getShadowUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightForwardFunctions"

bool getShadowFactorPointLight()
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(v_world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return false;
		
		if( shadow_depth < real_depth )
			return false;

		break;
	}
	return true;
}

bool isShadowed()	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(v_world_position,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	//adaptative bias
	vec3 N = normalize(v_normal);
	vec3 L;
	
	bool dark_outside; //add or not light outside the shadow map zone
	if(u_light_type == 0) {	//directional light
		L = -normalize(u_light_direction);
		dark_outside = false;
	}
	else if (u_light_type == 2){//spot
		L =  normalize(u_light_position - v_world_position);
		dark_outside = true;
	}
	else
		return !getShadowFactorPointLight();

	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - adaptative_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return dark_outside;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return dark_outside;
	
	//read depth from depth buffer in [0..+1]
	float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;
	
	if( shadow_depth < real_depth )
		return true;
	
	return false;
}

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	
	if (illumination_technique == 1) //PBR
	{
		//check if it is in shadow or not
		if (!isShadowed())
		{
			vec3 lightParams = computeLight(light);
			
			#include "PBRForwardCode"

			//function that returns the light using phong
			light += direct * lightParams;
		}
	}
	else //Phong
	{
		//check if it is in shadow or not
		if (!isShadowed())
			light += computeLight(light); //function that returns the light using phong
	}
	
	//add the ambient light
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number );
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz * u_emissive_factor;
	
	FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\lightAAShadows.fs

#version 330 core

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

#include "getTextureUniforms"

#include "getLightUniforms"

#include "getShadowUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightForwardFunctions"

float getShadowFactorPointLight()
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(v_world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return 0.0;
		
		if( shadow_depth < real_depth )
			return 0.0;

		break;
	}
	return 1.0;
}

float getShadowFactor()	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(v_world_position, 1.0);

	//from homogeneous space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//adaptative bias
	vec3 N = normalize(v_normal);
	vec3 L;
	if(u_light_type == 0) //directional light
		L = -normalize(u_light_direction);
	else if (u_light_type == 1)
		return getShadowFactorPointLight();
	else //spot
		L =  normalize(u_light_position - v_world_position);
		
	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);

	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1] (z)
	real_depth = real_depth * 0.5 + 0.5;

	//it is outside on the sides
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||
	shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			return 1.0;
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return 1.0;
	
	float xOffset = 1.0/u_shadowmap_width;
    float yOffset = 1.0/u_shadowmap_height;

	float Factor = 0.0;

    for (int y = -1 ; y <= 1 ; y++) {
        for (int x = -1 ; x <= 1 ; x++) {
            vec2 Offsets = vec2(x * xOffset, y * yOffset);
            vec3 UVC = vec3(shadow_uv + Offsets, real_depth);
            Factor += texture(u_shadowmap_AA, UVC);
        }
    }

    return (0.5 + (Factor / 18.0));
}

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	float shadowFact = getShadowFactor();

	if (illumination_technique == 1) //PBR
	{
		vec3 lightParams = shadowFact * computeLight(light);
		
		#include "PBRForwardCode"

		//function that returns the light using phong
		light += direct * lightParams;
	}
	else //Phong
		light += shadowFact * computeLight(light);
	
	//add the ambient light
	light += texture2D(u_occlusion_texture, uv * u_tiles_number).x * u_ambient_light; //ambient-occlusion filter applied

	color *= texture2D( u_texture, uv * u_tiles_number);
	if(color.a < u_alpha_cutoff)
		discard;

	//apply the light to the final pixel color
	color.xyz *= light;
	
	//emissive
	color.xyz += texture2D(u_emissive_texture, uv * u_tiles_number).xyz * u_emissive_factor;
	
	FragColor = color;
}
\blank
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// ------------------------------------------------------- DEFERRED --------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------
// -------------------------------------------------------------------------------------------------------------------------

\gbuffers.fs

#version 330

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

#include "getTextureUniforms"

uniform float u_roughness_factor;
uniform float u_metallic_factor;

uniform bool u_use_gamma_correction;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;
layout(location = 2) out vec4 EmissiveColor;

#include "gammaFunctions"

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	
	if(color.a < u_alpha_cutoff)
		discard;
	
	vec4 matProperties = texture( u_occlusion_texture, uv * u_tiles_number);
	vec4 emissive = texture( u_emissive_texture, uv * u_tiles_number) * vec4(u_emissive_factor, 1.0);
	
	vec4 texture_color = texture( u_texture, uv * u_tiles_number);
	
	if (u_use_gamma_correction) {
		EmissiveColor = vec4(gamma(emissive.xyz), matProperties.x);
		color.xyz *= gamma(texture_color.xyz);
	}
	else {
		EmissiveColor = vec4(emissive.xyz, matProperties.x);
		color.xyz *= texture_color.xyz;
	}
	
	//discard some pixels depending on the pixel screen position and its transparency
	if(	color.a < 0.9 && floor(mod(gl_FragCoord.x,2.0)) != floor(mod(gl_FragCoord.y,2.0)) )
		discard;

	FragColor = vec4(color.xyz, matProperties.z * u_metallic_factor);
	
	vec3 N = normalize(v_normal);
	NormalColor = vec4(N*0.5 + vec3(0.5), matProperties.y * u_roughness_factor);
	
	
	
}

// -------------------------------------------------------------------------------------------------------------------------

\deferred.fs

#version 330

#include "getDeferredUniforms"

uniform vec3 u_ambient_light;
uniform sampler2D u_ssao_texture;
uniform bool u_use_ssao;

uniform vec3 u_light_color;
uniform int u_light_type;
uniform vec3 u_light_direction;
uniform vec3 u_light_position;
uniform float u_light_intensity;

uniform vec3 u_irr_end;
uniform vec3 u_irr_start;
uniform vec3 u_irr_delta;
uniform vec3 u_irr_dims;
uniform float u_irr_normal_distance;
uniform int u_num_probes;
uniform sampler2D u_probes_texture;

uniform bool u_use_irradiance;
uniform bool u_interpolate_probes;

layout(location = 0) out vec4 FragColor;

#include "shCode"

vec3 getDirectionalLight(vec3 N)
{
	//if the light is a directional light the light vector is the same for all pixels
	vec3 L = normalize(-u_light_direction);	//light vector goes in opposite direction
		
	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	
	return NdotL * u_light_color * u_light_intensity;
}

vec3 interpolateIrradiances(vec3 irradiances[8], vec3 factors)
{
	vec3 i00 = mix(irradiances[0], irradiances[1], factors.x);
	vec3 i01 = mix(irradiances[2], irradiances[3], factors.x);
	vec3 i10 = mix(irradiances[4], irradiances[5], factors.x);
	vec3 i11 = mix(irradiances[6], irradiances[7], factors.x);
	
	vec3 i0 = mix(i00, i10, factors.y);
	vec3 i1 = mix(i01, i11, factors.y);
	
	return mix(i0, i1, factors.z);
}

vec3 getIrradiance(vec3 worldpos, vec3 N)
{
	//computing nearest probe index based on world position
	vec3 irr_range = u_irr_end - u_irr_start;
	vec3 grid_pos = worldpos - u_irr_start;
	vec3 irr_local_pos = clamp( worldpos - u_irr_start
+ N * u_irr_normal_distance * u_irr_delta, //offset a little
	 vec3(0.0), irr_range );
	 
	if (grid_pos.x < 0 || grid_pos.y < 0 || grid_pos.z < 0
	|| grid_pos.x > irr_range.x || grid_pos.y > irr_range.y || grid_pos.z > irr_range.z)
		return vec3(0,0,0);
	
	//convert from world pos to grid pos
	vec3 irr_norm_pos = irr_local_pos / u_irr_delta;
	
	vec3 local_indices = vec3(0.0);
	
	if (u_interpolate_probes)	// interpolate
	{
		//floor instead of round
		local_indices = floor( irr_norm_pos );

		//now we have the interpolation factors
		vec3 factors = irr_norm_pos - local_indices; 
		
		//now fetch the SHs for all 8 probes and do a trilinear interpolation
		
		vec3 irradiances[8];
		vec3 positions[8] = vec3[](vec3(0,0,0), vec3(1,0,0), vec3(0,0,1), vec3(1,0,1), 
									vec3(0,1,0), vec3(1,1,0), vec3(0,1,1), vec3(1,1,1));
									
		for (int i = 0; i < 8; i++)
		{
			vec3 local_indices_aux = local_indices + positions[i];
			//compute in which row is the probe stored
			float row = local_indices_aux.x + local_indices_aux.y * u_irr_dims.x + local_indices_aux.z * u_irr_dims.x * u_irr_dims.y;

			//find the UV.y coord of that row in the probes texture
			float row_uv = (row + 1.0) / (u_num_probes + 1.0);
			
			SH9Color sh;

			//fill the coefficients
			const float d_uvx = 1.0 / 9.0;
			for(int i = 0; i < 9; ++i)
			{
				vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
				sh.c[i] = texture( u_probes_texture, coeffs_uv).xyz;
			}

			//now we can use the coefficients to compute the irradiance
			irradiances[i] = ComputeSHIrradiance( N, sh );
		}
		
		return interpolateIrradiances(irradiances, factors);
	}
	else
	{
		//round values as we cannot fetch between rows for now
		local_indices = round( irr_norm_pos );

		//compute in which row is the probe stored
		float row = local_indices.x + local_indices.y * u_irr_dims.x + local_indices.z * u_irr_dims.x * u_irr_dims.y;

		//find the UV.y coord of that row in the probes texture
		float row_uv = (row + 1.0) / (u_num_probes + 1.0);
		
		SH9Color sh;

		//fill the coefficients
		const float d_uvx = 1.0 / 9.0;
		for(int i = 0; i < 9; ++i)
		{
			vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
			sh.c[i] = texture( u_probes_texture, coeffs_uv).xyz;
		}

		//now we can use the coefficients to compute the irradiance
		return ComputeSHIrradiance( N, sh );
	}
}

void main()
{
	#include "reconstructFromGBuffers"
	
	vec3 light = vec3(0.0);
	vec3 ambient_light = (depth >= 1) ? vec3(1.0) : u_ambient_light;
	
	if (u_use_ssao)
	{
		//read the ao_factor for this pixel
		float ao_factor = texture( u_ssao_texture, uv ).x;

		//we could play with the curve to have more control
		ao_factor = pow( ao_factor, 3.0 );

		//weight the ambient light by it
		light += ao_factor * ambient_light;
	}
	else 
		light += texture(u_emissive_texture, uv).w * ambient_light;
	
	//light += getDirectionalLight(N);
	
	color *= light;
	
	//irradiance
	if (u_use_irradiance)
		color += getIrradiance(worldpos, N) * 0.2;

	//emissive
	color.xyz += texture2D(u_emissive_texture, uv).xyz;
	
	FragColor = vec4(color, 1.0);
}

// -------------------------------------------------------------------------------------------------------------------------

\deferredBlend.fs

#version 330

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

#include "getTextureUniforms"

#include "getLightUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightForwardFunctions"

void main()
{
	vec4 color = u_color;
	vec2 uv = v_uv;
	vec2 uv_gbuffer = (gl_FragCoord.xy) * u_iRes.xy; //extract uvs from pixel screenpos
	
	color *= texture( u_texture, uv * u_tiles_number);
	float depth = texture( u_depth_texture, uv_gbuffer ).x;
	
	vec3 light = vec3(0.0);

	if (depth < gl_FragCoord.z) {
		discard;
	}
	
	if (illumination_technique == 1) //PBR
	{
		vec3 lightParams = computeLight(light);
		
		#include "PBRForwardCode"

		//function that returns the light using phong
		light += direct * lightParams;
	}
	else //Phong
		light += computeLight(light);
	
	light += texture2D(u_occlusion_texture, v_uv * u_tiles_number).x * u_ambient_light;
	
	//apply the light to the final pixel color
	color.xyz *= light;
	
	FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\deferredLight.fs

#version 330 core

#include "getDeferredUniforms"

#include "getLightUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightDeferredFunctions"

void main()
{
	#include "reconstructFromGBuffers"

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	if (illumination_technique == 1) // PBR
	{
		vec3 lightParams = computeLight(light, N, worldpos);
		
		#include "PBRDeferredCode"

		//function that returns the light using phong
		light += direct * lightParams;
	}
	else // Phong
		light += computeLight(light, N, worldpos);
	
	//apply the light to the final pixel color
	color.xyz *= light;
	
	FragColor = vec4(color, 1.0);
	return;
}

// -------------------------------------------------------------------------------------------------------------------------

\deferredBlendShadows.fs

#version 330

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

#include "getTextureUniforms"

#include "getLightUniforms"

#include "getShadowUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightForwardFunctions"

bool getShadowFactorPointLight()
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(v_world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return false;
		
		if( shadow_depth < real_depth )
			return false;

		break;
	}
	return true;
}

bool isShadowed()	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(v_world_position,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	//adaptative bias
	vec3 N = normalize(v_normal);
	vec3 L;
	
	bool dark_outside; //add or not light outside the shadow map zone
	if(u_light_type == 0) {	//directional light
		L = -normalize(u_light_direction);
		dark_outside = false;
	}
	else if (u_light_type == 2){//spot
		L =  normalize(u_light_position - v_world_position);
		dark_outside = true;
	}
	else
		return !getShadowFactorPointLight();

	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - adaptative_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return dark_outside;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return dark_outside;
	
	//read depth from depth buffer in [0..+1]
	float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;
	
	if( shadow_depth < real_depth )
		return true;
	
	return false;
}

void main()
{
	vec4 color = u_color;
	vec2 uv = v_uv;
	vec2 uv_gbuffer = (gl_FragCoord.xy) * u_iRes.xy; //extract uvs from pixel screenpos
	
	color *= texture( u_texture, uv * u_tiles_number);
	float depth = texture( u_depth_texture, uv_gbuffer ).x;
	
	vec3 light = vec3(0.0);

	if (depth < gl_FragCoord.z) {
		discard;
	}
	
	if (illumination_technique == 1) //PBR
	{
		//check if it is in shadow or not
		if (!isShadowed())
		{
			vec3 lightParams = computeLight(light);
			
			#include "PBRForwardCode"

			//function that returns the light using phong
			light += direct * lightParams;
		}
	}
	else //Phong
	{
		//check if it is in shadow or not
		if (!isShadowed())
			light += computeLight(light); //function that returns the light using phong
	}
	
	light += texture2D(u_occlusion_texture, v_uv * u_tiles_number).x * u_ambient_light;
	
	//apply the light to the final pixel color
	color.xyz *= light;
	
	FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\deferredLightShadows.fs

#version 330 core

#include "getDeferredUniforms"

#include "getLightUniforms"

#include "getShadowUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightDeferredFunctions"

bool getShadowFactorPointLight(vec3 world_position)
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return false;
		
		if( shadow_depth < real_depth )
			return false;

		break;
	}
	return true;
}

bool isShadowed(vec3 world_position, vec3 normal)	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(world_position,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	//adaptative bias
	vec3 N = normalize(normal);
	vec3 L;
	
	bool dark_outside; //add or not light outside the shadow map zone
	if(u_light_type == 0) {	//directional light
		L = -normalize(u_light_direction);
		dark_outside = false;
	}
	else if (u_light_type == 2){//spot
		L =  normalize(u_light_position - world_position);
		dark_outside = true;
	}
	else
		return !getShadowFactorPointLight(world_position);

	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - adaptative_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return dark_outside;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return dark_outside;
	
	//read depth from depth buffer in [0..+1]
	float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;
	
	if( shadow_depth < real_depth )
		return true;
	
	return false;
}

void main()
{
	#include "reconstructFromGBuffers"

	//here we can store the total amount of light
	vec3 light = vec3(0.0);
	
	if (illumination_technique == 1) //PBR
	{
		//check if it is in shadow or not
		if (!isShadowed(worldpos, N))
		{
			vec3 lightParams = computeLight(light, N, worldpos);
			
			#include "PBRDeferredCode"

			//function that returns the light using phong
			light += direct * lightParams;
		}
	}
	else //Phong
	{
		//check if it is in shadow or not
		if (!isShadowed(worldpos, N))
			light += computeLight(light, N, worldpos); //function that returns the light using phong
	}

	//apply the light to the final pixel color
	color.xyz *= light;
	
	FragColor = vec4(color, 1.0);
}

// -------------------------------------------------------------------------------------------------------------------------

\deferredBlendAAShadows.fs

#version 330

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

#include "getTextureUniforms"

#include "getLightUniforms"

#include "getShadowUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightForwardFunctions"

float getShadowFactorPointLight()
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(v_world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return 0.0;
		
		if( shadow_depth < real_depth )
			return 0.0;

		break;
	}
	return 1.0;
}

float getShadowFactor()	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(v_world_position, 1.0);

	//from homogeneous space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//adaptative bias
	vec3 N = normalize(v_normal);
	vec3 L;
	if(u_light_type == 0) //directional light
		L = -normalize(u_light_direction);
	else if (u_light_type == 1)
		return getShadowFactorPointLight();
	else //spot
		L =  normalize(u_light_position - v_world_position);
		
	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);

	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1] (z)
	real_depth = real_depth * 0.5 + 0.5;

	//it is outside on the sides
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||
	shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			return 1.0;
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return 1.0;
	
	float xOffset = 1.0/u_shadowmap_width;
    float yOffset = 1.0/u_shadowmap_height;

	float Factor = 0.0;

    for (int y = -1 ; y <= 1 ; y++) {
        for (int x = -1 ; x <= 1 ; x++) {
            vec2 Offsets = vec2(x * xOffset, y * yOffset);
            vec3 UVC = vec3(shadow_uv + Offsets, real_depth);
            Factor += texture(u_shadowmap_AA, UVC);
        }
    }

    return (0.5 + (Factor / 18.0));
}

void main()
{
	vec4 color = u_color;
	vec2 uv = v_uv;
	vec2 uv_gbuffer = (gl_FragCoord.xy) * u_iRes.xy; //extract uvs from pixel screenpos
	
	color *= texture( u_texture, uv * u_tiles_number);
	float depth = texture( u_depth_texture, uv_gbuffer ).x;
	
	vec3 light = vec3(0.0);

	if (depth < gl_FragCoord.z) {
		discard;
	}
	
	float shadowFact = getShadowFactor();

	if (illumination_technique == 1) //PBR
	{
		vec3 lightParams = shadowFact * computeLight(light);
		
		#include "PBRForwardCode"

		//function that returns the light using phong
		light += direct * lightParams;
	}
	else //Phong
		light += shadowFact * computeLight(light);
	
	light += texture2D(u_occlusion_texture, v_uv * u_tiles_number).x * u_ambient_light;
	
	//apply the light to the final pixel color
	color.xyz *= light;
	
	FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\deferredLightAAShadows.fs

#version 330 core

#include "getDeferredUniforms"

#include "getLightUniforms"

#include "getShadowUniforms"

out vec4 FragColor;

#include "PBRFunctions"

#include "lightDeferredFunctions"

#include "gammaFunctions"

float getShadowFactorPointLight(vec3 world_position)
{
	const float i_offset = 1.0 / 6.0;
	for (int i = 0; i < 6; i++) {
		
		mat4 shadowmap_viewproj = mat4(1.0);
		vec4 proj_pos = u_shadowmap_viewprojs[i] * vec4(world_position,1.0);
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		//it is outside on the sides, try next face
		if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			continue;

		shadow_uv.x *= i_offset;
		shadow_uv.x += i_offset * float(i);
		
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		real_depth = real_depth * 0.5 + 0.5;
		
		float shadow_depth = texture2D(u_shadowmap, shadow_uv).x;

		if(real_depth < 0.0 || real_depth > 1.0)
			return 0.0;
		
		if( shadow_depth > real_depth )
			return 1.0;
		
		float xOffset = 1.0/u_shadowmap_width;
		float yOffset = 1.0/u_shadowmap_height;

		float Factor = 0.0;

		for (int y = -1 ; y <= 1 ; y++) {
			for (int x = -1 ; x <= 1 ; x++) {
				vec2 Offsets = vec2(x * xOffset, y * yOffset);
				vec3 UVC = vec3(shadow_uv + Offsets, real_depth);
				Factor += texture(u_shadowmap_AA, UVC);
			}
		}

		return (0.5 + (Factor / 18.0));
	}
	return 1.0;
}

float getShadowFactor(vec3 world_position, vec3 normal)	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(world_position,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	//adaptative bias
	vec3 N = normalize(normal);
	vec3 L;
	
	float light_outside = 1.0; //add or not light outside the shadow map zone
	if(u_light_type == 0) {	//directional light
		L = -normalize(u_light_direction);
		light_outside = 1.0;
	}
	else if (u_light_type == 2) { //spot
		L =  normalize(u_light_position - world_position);
		light_outside = 0.0;
	}
	else
		return getShadowFactorPointLight(world_position);
	
	float NdotL = clamp(dot(N,L), 0.0, 1.0);
	//compute the new adaptative bias
	float adaptative_bias = u_shadow_bias * tan(acos(NdotL));
	//adaptative_bias = clamp(adaptative_bias, 0.0, 1.0);
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - adaptative_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return light_outside;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return light_outside;
	
	float xOffset = 1.0/u_shadowmap_width;
    float yOffset = 1.0/u_shadowmap_height;

	float Factor = 0.0;

    for (int y = -1 ; y <= 1 ; y++) {
        for (int x = -1 ; x <= 1 ; x++) {
            vec2 Offsets = vec2(x * xOffset, y * yOffset);
            vec3 UVC = vec3(shadow_uv + Offsets, real_depth);
            Factor += texture(u_shadowmap_AA, UVC);
        }
    }
    return (0.5 + (Factor / 18.0));
}

void main()
{
	#include "reconstructFromGBuffers"

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	float shadowFact = getShadowFactor(worldpos, N);

	if (illumination_technique == 1) //PBR
	{
		vec3 lightParams = shadowFact * computeLight(light, N, worldpos);
		
		#include "PBRDeferredCode"

		//function that returns the light using phong
		light += direct * lightParams;
	}
	else //Phong
		light += shadowFact * computeLight(light, N, worldpos);

	//apply the light to the final pixel color
	color.xyz *= light;

	FragColor = vec4(color, 1.0);
}

// -------------------------------------------------------------------------------------------------------------------------

\degammaDeferred.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
out vec4 FragColor;

#include "gammaFunctions"

void main()
{
	vec4 color = texture(u_texture, v_uv);
	FragColor = vec4(degamma(color.xyz), color.w);
}


\ssao.fs

#version 330 core

in vec2 v_uv;

#include "getDeferredUniforms"
uniform vec3[100] u_points;
uniform mat4 u_viewprojection;
uniform float u_radius;

out vec4 FragColor;

mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}

void main()
{
    //we want to center the sample in the center of the pixel
    vec2 uv = v_uv + u_iRes * 0.5;

    //read depth from depth buffer
    float depth = texture( u_depth_texture, uv ).x;
	vec3 normal = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	normal = normalize(normal);

    //ignore pixels in the background
    if(depth >= 1.0)
    {
        FragColor = vec4(1.0);
        return;
    }

    //create screenpos with the right depth
    vec4 screen_position = vec4(uv * 2.0 - vec2(1.0), depth * 2.0 - 1.0, 1.0);

    //reproject
    vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
    vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

    //lets use 64 samples
    const int samples = 100;
    int num = samples; //num samples that passed the are outside

    //for every sample around the point
    for( int i = 0; i < samples; ++i )
    {
		//to create the matrix33 to convert from tangent to world
		mat3 rotmat = cotangent_frame( normal, worldpos, uv );

		//rotate a point is easy
		vec3 rotated_point = rotmat * u_points[i];

        //compute is world position using the random
        vec3 p = worldpos + rotated_point * u_radius;
        //find the uv in the depth buffer of this point
        vec4 proj = u_viewprojection * vec4(p,1.0);
        proj.xy /= proj.w; //convert to clipspace from homogeneous
        //apply a tiny bias to its z before converting to clip-space
        proj.z = (proj.z - 0.005) / proj.w;
        proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]
        //read p true depth
        float pdepth = texture( u_depth_texture, proj.xy ).x;
        //compare true depth with its depth
        if( pdepth < proj.z ) //if true depth smaller, is inside
            num--; //remove this point from the list of visible
    }

    //finally, compute the AO factor accordingly
    float ao = float(num) / float(samples);

    FragColor = vec4(ao, ao, ao, 1.0);

}


\blur.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform int u_kernel_size;
uniform vec2 u_offset;

out vec4 FragColor;

void main ()
{
	vec2 uv = v_uv;
	vec4 color = vec4(0.0);
	int half_kernel = int(floor(u_kernel_size/2.0));
	for (int i = -half_kernel; i <= half_kernel; i++)
		for (int j = -half_kernel; j <= half_kernel; j++)
			color += texture2D(u_texture, uv + u_offset * vec2(i,j));
	color /= pow(u_kernel_size, 2);
	FragColor = color;
}


\probe.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

#include "getTextureUniforms"
uniform vec3 u_coeffs[9];

uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec2 u_iRes;

out vec4 FragColor;

#include "shCode"

void main()
{
	// scene depth
	vec2 uv = (gl_FragCoord.xy + 0.5) * u_iRes.xy; //extract uvs from pixel screenpos
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	
	// probe depth
	vec3 p = v_world_position;
	vec4 proj = u_viewprojection * vec4(p,1.0);
	proj.z = (proj.z - 0.005) / proj.w;
	
	if( screen_pos.z < proj.z )
		discard;
		 
	SH9Color sh;
	
	for (int i=0; i < 9; i++)
		sh.c[i] = u_coeffs[i];
	
	vec3 N = normalize(v_normal);
	vec3 irradiance = ComputeSHIrradiance( N, sh );

	FragColor = vec4(irradiance, 1.0);
}

\reflectionProbe.fs

#version 330 core

in vec3 v_world_position;
in vec3 v_normal;
in vec4 v_color;

uniform vec3 u_camera_position;
uniform samplerCube u_cubemap_texture;

out vec4 FragColor;

void main()
{
	vec3 N = normalize( v_normal );
	vec3 V = normalize( u_camera_position - v_world_position );

	vec3 R = reflect( -V, N );

	//compute the reflection
	vec3 reflection = textureLod( u_cubemap_texture, R, 0.0 ).xyz;

	//set the metalness as alpha
	FragColor = vec4( reflection, 1.0 );
}


\reflection.fs

#version 330 core

in vec3 v_world_position;
in vec3 v_normal;
in vec4 v_color;
in vec2 v_uv;

uniform vec3 u_camera_position;
uniform samplerCube u_cubemap_texture;

#include "getDeferredUniforms"

uniform vec3 u_probes_positions[10];
uniform samplerCube u_cubemap_0;
uniform samplerCube u_cubemap_1;
uniform samplerCube u_cubemap_2;
uniform samplerCube u_cubemap_3;
uniform samplerCube u_cubemap_4;
uniform samplerCube u_cubemap_5;
uniform samplerCube u_cubemap_6;
uniform samplerCube u_cubemap_7;
uniform samplerCube u_cubemap_8;
uniform samplerCube u_cubemap_9;

uniform float u_normal_distance;

out vec4 FragColor;



void main()
{
    #include "reconstructFromGBuffers"
	
	vec3 V = normalize( u_camera_position - worldpos );

	vec3 R = reflect( -V, N );
	
	float metalness = texture( u_color_texture, uv ).w;
	float roughness = texture( u_normal_texture, uv ).w;
	
	float min_dist = 400;
	int closest_probe_idx = -1;
	for (int i=0; i<10; i++) //compute the nearest reflection probe
	{
		float curr_dist = length(u_probes_positions[i] - (worldpos + u_normal_distance * N));
		if (curr_dist < min_dist)
		{
			min_dist = curr_dist;
			closest_probe_idx = i;
		}
	}
	
	vec3 reflection = vec3(0.0);
	
	if (closest_probe_idx == 0)
		reflection = textureLod( u_cubemap_0, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 1)
		reflection = textureLod( u_cubemap_1, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 2)
		reflection = textureLod( u_cubemap_2, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 3)
		reflection = textureLod( u_cubemap_3, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 4)
		reflection = textureLod( u_cubemap_4, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 5)
		reflection = textureLod( u_cubemap_5, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 6)
		reflection = textureLod( u_cubemap_6, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 7)
		reflection = textureLod( u_cubemap_7, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 8)
		reflection = textureLod( u_cubemap_8, R, roughness * 5.0 ).xyz;
	else if (closest_probe_idx == 9)
		reflection = textureLod( u_cubemap_9, R, roughness * 5.0 ).xyz;
	else
	{
		//avoid misleading information on points far to proves
		FragColor = vec4( 0.0 );
		return;
	}
	
	//atenuation factor for reaching the threshold progressively?
	FragColor = vec4( reflection, metalness * metalness );// * (1 - min_dist / 400);
	
}


\skybox.fs

#version 330 core
in vec3 v_world_position;

uniform samplerCube u_texture;
uniform vec3 u_camera_position;

out vec4 FragColor;

void main()
{
	vec3 V = normalize( u_camera_position - v_world_position );

	FragColor = texture( u_texture, V );
}


\volumetric.fs

#version 330 core
in vec3 v_world_position;

uniform vec3 u_camera_position;
uniform int u_quality;
uniform float u_air_density;
uniform float u_clamp;
uniform sampler2D u_noise_tex;
uniform vec3 u_random;

uniform mat4 u_inverse_viewprojection;
uniform sampler2D u_depth_texture;
uniform vec2 u_iRes;

#define NUM_LIGHTS 3

uniform vec3 u_light_position[NUM_LIGHTS];
uniform vec3 u_light_color[NUM_LIGHTS];
uniform float u_light_maxdist[NUM_LIGHTS];
uniform float u_light_intensity[NUM_LIGHTS];
uniform int u_light_type[NUM_LIGHTS];
uniform float u_light_spotCosineCutoff[NUM_LIGHTS];
uniform float u_light_spotExponent[NUM_LIGHTS];
uniform vec3 u_light_direction[NUM_LIGHTS];
uniform float u_shadow_bias[NUM_LIGHTS];
uniform mat4 u_shadow_viewproj[NUM_LIGHTS];
uniform sampler2D u_shadowmap1;
uniform sampler2D u_shadowmap2;
uniform sampler2D u_shadowmap3;

out vec4 FragColor;

float getAttenuation(vec3 world_position, int i_light)
{	
	if (u_light_type[i_light] == 0) //directionals dont have att
		return 1.0; 

	//compute distance
	float light_distance = length(u_light_position[i_light] - world_position);

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist[i_light] - light_distance;

	//normalize factor
	att_factor /= u_light_maxdist[i_light];

	//ignore negative values
	att_factor = max( att_factor, 0.0 );
	
	//quadratic att factor
	att_factor *= att_factor;

	//apply to amount of light
	return att_factor;
}

vec3 getLight(vec3 world_position, int i_light)
{
	if (u_light_type[i_light] == 0) //directional
	{
		return u_light_color[i_light] * u_light_intensity[i_light];
	}
	else //spot
	{
		//light vector
		vec3 L = normalize(u_light_position[i_light] - world_position);
		vec3 D = normalize(u_light_direction[i_light]);
		float spotCosine = dot(D, -L);
		if (spotCosine >= u_light_spotCosineCutoff[i_light])
			return u_light_color[i_light] * pow(spotCosine, u_light_spotExponent[i_light]) * u_light_intensity[i_light];
		else 
			return vec3(0.0); //out of the focus
	}
}


float getShadowFactor(vec3 pos, int i_light)	// returns if point is shadowed
{
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj[i_light] * vec4(pos, 1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);
	
	float shadow_fac; //add or not light outside the shadow map zone
	if(u_light_type[i_light] == 0) {	//directional light
		shadow_fac = 1.0;
	}
	else if (u_light_type[i_light] == 2) { //spot
		shadow_fac = 0.0;
	}
	
	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - u_shadow_bias[i_light]) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;
	
	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		return shadow_fac;	
	//it is outside on the sides
	if(shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		return shadow_fac;
	
	//read depth from depth buffer in [0..+1]
	float shadow_depth;
	if (i_light == 0) shadow_depth = texture2D(u_shadowmap1, shadow_uv).x;
	else if (i_light == 1) shadow_depth = texture2D(u_shadowmap2, shadow_uv).x;
	else if (i_light == 2) shadow_depth = texture2D(u_shadowmap3, shadow_uv).x;
	
	if( shadow_depth < real_depth )
		return 0.0;
	
	return 1.0;
}

void main()
{
	// reconstruct points
	vec2 uv = gl_FragCoord.xy * u_iRes; //extract uvs from pixel screenpos
	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	// init volumetric
	vec3 ray_pos = u_camera_position;
	vec3 dist = worldpos - ray_pos;
	vec3 step = dist/u_quality;
	float noise = texture2D(u_noise_tex, uv * u_random.xy).x;
	ray_pos += normalize(dist) * noise;
	
	float d = clamp(length(step), 0.0, u_clamp);
	vec3 acc_color = vec3(0.0);
	float acc_density = 0.0;
	float sample_attenuation = d * u_air_density;

	for (int i = 1; i < 10000; i++)
	{
		//for every light
		for(int j = 0; j < NUM_LIGHTS; ++j)
		{
			float shadow_factor = getShadowFactor(ray_pos, j);
			if (shadow_factor != 0.0)
			{
				float att_factor = getAttenuation(ray_pos, j);
				vec3 light = getLight(ray_pos, j);
				acc_color += (sample_attenuation * light * shadow_factor * att_factor);
				acc_density += (sample_attenuation * (length(light) * u_light_intensity[j]) * shadow_factor * att_factor);
			}
		}

		if (acc_density >= 1.0)
			break;
		if (i == u_quality)
			break;
		ray_pos += step;
	}

	FragColor = vec4(acc_color, acc_density);
}


\decal.fs

#version 330

in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform sampler2D u_texture;
uniform sampler2D u_texture_material;
uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;

uniform float u_roughness_factor;
uniform float u_metallic_factor;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

uniform mat4 u_imodel;
uniform vec3 u_camera_pos;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;
layout(location = 2) out vec4 EmissiveColor;

void main()
{
	vec2 uv = (gl_FragCoord.xy) * u_iRes; //extract uvs from pixel screenpos
	
	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec3 normal = texture( u_normal_texture, uv ).xyz;
	
	if (depth >= 1)
		discard;
	
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	vec3 V = normalize( worldpos - u_camera_pos );
	
	vec3 decal_pos = (u_imodel * vec4(worldpos, 1.0)).xyz;
	vec2 decal_uv = decal_pos.xz * 0.5 + vec2(0.5);
	
	if (decal_uv.x < 0 || decal_uv.x > 1 || decal_uv.y < 0 || decal_uv.y > 1)
		discard;
	
	//vec4 texture_color = texture( u_texture, decal_uv );
	vec3 texture_color = texture( u_texture, decal_uv ).xyz;
	vec4 texture_material = texture( u_texture_material, decal_uv );
	
	float occlusion = texture_material.x;
	float roughness = texture_material.y * u_roughness_factor;
	float metalness = texture_material.z * u_metallic_factor;

	//'blending' will add this to the current buffers
	FragColor = vec4(texture_color, metalness);
	NormalColor = vec4(normal, roughness);
	EmissiveColor = vec4(vec3(0.0), occlusion);
	//FragColor = vec4(texture_color);
	//NormalColor = vec4(0.0);
	//EmissiveColor = vec4(0.0);
}


\toneMapper.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform float u_average_lum;
uniform float u_lumwhite2;
uniform float u_igamma;
uniform float u_scale;

out vec4 FragColor;

#include "gammaFunctions"

vec3 RGB2xyY (vec3 rgb)
{
	const mat3 RGB2XYZ = mat3(0.4124, 0.3576, 0.1805,
							   0.2126, 0.7152, 0.0722,
							   0.0193, 0.1192, 0.9505);
	vec3 XYZ = RGB2XYZ * rgb;
	float f = (XYZ.x + XYZ.y + XYZ.z);

	return vec3(XYZ.x / f,
				XYZ.y / f,
				XYZ.y);
}

void main() {
	vec4 color = texture2D(u_texture, v_uv);
	vec3 rgb = color.xyz;

	float lum = dot(rgb, vec3(0.2126, 0.7152, 0.0722));
	float L = (u_scale / u_average_lum) * lum;
	float Ld = (L * (1.0 + L / u_lumwhite2)) / (1.0 + L);

	rgb = (rgb / lum) * Ld;
	rgb = max(rgb,vec3(0.001));
	rgb = pow( rgb, vec3( u_igamma ) );
	FragColor = vec4( rgb, color.a );
}